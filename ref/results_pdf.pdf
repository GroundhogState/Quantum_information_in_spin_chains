<h1 id="contents">Contents</h1>
<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->
<ul>
<li><a href="#contents">Contents</a></li>
<li><a href="#graph-structure">Graph structure</a>
<ul>
<li><a href="#weight-distribution">Weight distribution</a></li>
<li><a href="#degree-distribution">Degree distribution</a></li>
</ul></li>
<li><a href="#the-laplacian">The Laplacian</a> - <a href="#properties-of-the-laplacian">Properties of the Laplacian</a>
<ul>
<li><a href="#spectral-distribution">Spectral distribution</a></li>
<li><a href="#trace-distribution">Trace distribution</a></li>
<li><a href="#entropy-distributions">Entropy distributions</a></li>
</ul></li>
<li><a href="#properties-of-aleph">Properties of <span class="math inline">ℵ</span></a>
<ul>
<li><a href="#spectrum">Spectrum</a></li>
<li><a href="#trace">Trace</a></li>
</ul></li>
<li><a href="#">=============================================================================</a></li>
<li><a href="#todo">TODO</a></li>
<li><a href="#centrality">Centrality</a></li>
</ul>
<!-- /TOC -->
<h1 id="graph-structure">Graph structure</h1>
<p>A graph is a tuple <span class="math inline">(<em>V</em>, <em>W</em>)</span> of a set of vertices <span class="math inline"><em>v</em> ∈ <em>V</em>, |<em>V</em>| = <em>N</em></span> with a matrix W of <em>weights</em>, <span class="math inline"><em>W</em> : <em>V</em> × <em>V</em> ↦ ℝ<sup><em>N</em> × <em>N</em></sup></span> <span class="math inline"><em>W</em><em>i</em>, <em>j</em>, <em>i</em> ≠ <em>j</em></span> is the mutual information between spin <span class="math inline"><em>i</em></span> and <span class="math inline"><em>j</em></span>, and <span class="math inline"><em>W</em><sub><em>i</em>, <em>i</em></sub></span> has several useful definitions.</p>
<h2 id="weight-distribution">Weight distribution</h2>
<p>Define the <em>adjacency matrix</em> <span class="math inline">ℷ</span> as the matrix $W $ with a zero diagonal, describing only the non-self connections.</p>
<p>Define the entropy <span class="math inline"><em>Ω</em></span> of a histogram by Jayne’s formula for the limiting density of discrete points,</p>
<p><br /><span class="math display"><em>Ω</em> =  − ∑<sub><em>i</em> = 1, …, <em>N</em></sub><em>p</em>(<em>x</em><sub><em>i</em></sub>)log <em>p</em>(<em>x</em><sub><em>i</em></sub>)<em>d</em><em>x</em><sub><em>i</em></sub></span><br /></p>
<p>Which is the discrete approximation of the entropy of a continuous probability density function, defined on a histogram of <span class="math inline"><em>N</em></span> bins with widths <span class="math inline"><em>d</em><em>x</em><sub><em>i</em></sub></span>.</p>
<p><img src="C:\Users\jaker\Documents\ent_loc\dat\ent_data\L13_dat\out\02_Weight_distribution.png" /></p>
<pre><code>The entropy (see main body) of the weight distribution (top left)
shown versus disorder strength.
Log-probability distributions for the MI of spin pairs (lower left)
and the base-10 logarithm of the MI of spin pairs. (right column),
shown on linear (top row0 and logarithmic (middle row) scales.
</code></pre>
<p>In the localized phase, the weight distribution is sharply peaked. In the localized phase, the distribution is visible broader, with many more edges at much lower strengths than the localized phase (note the negative log in the horizontal axis). CDF to be included in appendix.</p>
<h2 id="degree-distribution">Degree distribution</h2>
<p>Define the <em>degree</em> of a node in a graph by the sum of the weights of all the edges connected to it, <span class="math inline">ℸ<sub><em>i</em></sub> = ∑<sub><em>j</em></sub>ℷ<sub><em>i</em><em>j</em></sub></span>, i.e the sum of the <span class="math inline"><em>i</em></span>th row of the adjacency matrix (for undirected graphs, this is also the column sum).</p>
<figure>
<img src="C:\Users\jaker\Documents\ent_loc\dat\ent_data\L13_dat\out\01_Degree_distribution.png" title="Logo Title Text 1" alt="alt text" /><figcaption>alt text</figcaption>
</figure>
<pre><code>Probability distributions for the degree (left)
and the base-10 logarithm of the degree (right),
shown on linear (top row0 and logarithmic (middle row).
Also, the entropy (in Jaynes&#39; sense) of these distrutions (bottom row)
 shown versus disorder strength
</code></pre>
<p>In the extended phase, most nodes are equally well connected, with some more strongly than the mode. In the extended phase, most degrees are quite weak, reflecting poorly-connected nodes, with a small probability of being more strongly connected. The log-log plot suggests a power-law scaling of the probability of finding a node with a given degree, which is characteristic of scale-free graphs. Notice that for small disorder strength past the onset of localization, the mode of the degree distribution actually increases, suggesting a strengthening of the overall mutual information integration (CLARIFY) in the system. The degree distribution exhibits a much clearer distinction thann the weight distribution between the localized and extended phases in its density diagram. Moreover, the probability distributions themselves have markedly different shapes, but I propose they are parametrized by a single probability distribution.</p>
<h1 id="the-laplacian">The Laplacian</h1>
<p>Define the <em>Laplacian</em> of the graph by</p>
<p><br /><span class="math display"><em>L</em> = ℸ − ℷ</span><br /></p>
<p>One can furnish the definition of <span class="math inline">ℷ</span> by constructing the <em>Laplacian</em> of the graph, defined by where <span class="math inline">ℸ</span> is the diagonal matrix whose <span class="math inline"><em>i</em><em>i</em></span>th entry is the degree of node <span class="math inline"><em>i</em></span>. #### Properties of the Laplacian * Discretized continuum Laplacian * Graph partitioning * Relation to graph Fourier transforms * the number of zero eigenvalues of <span class="math inline"><em>L</em></span> is the number of connected components in the graph}. * For a disjoint union of <span class="math inline"><em>k</em></span> graphs, then, the spectrum of <span class="math inline"><em>L</em></span> has a <span class="math inline"><em>k</em></span>-degenerate null space. * Equivalently, one can block-diagonalize both <span class="math inline">ℷ</span> and <span class="math inline"><em>L</em></span> with one matrix block for each connected component.</p>
<h2 id="spectral-distribution">Spectral distribution</h2>
<figure>
<img src="C:\Users\jaker\Documents\ent_loc\dat\ent_data\L13_dat\out\04_Laplacian_spectral_distribution.png" alt="lapspec" /><figcaption>lapspec</figcaption>
</figure>
<pre><code>Probability distributions of the eigenvalues of the Laplacian (upper &amp; mid left),
the PDFs of the log of the eigenvalues (upper &amp; mid right),
and the Shannon entropy (lower row) of the distributions versus disorder.
Lighter colours are higher disorder strengths.
What&#39;s up with lower right?!</code></pre>
<p>Note the similarity to the degree distribution.</p>
<h2 id="trace-distribution">Trace distribution</h2>
<figure>
<img src="C:\Users\jaker\Documents\ent_loc\dat\ent_data\L13_dat\out\05_Laplacian_trace_distribution.png" alt="tracedist" /><figcaption>tracedist</figcaption>
</figure>
<pre><code>Probability distributions of the trace of the Laplacian (upper &amp; mid left),
the PDFs of the log of the trace (upper &amp; mid right),
and the Shannon entropy (lower row) of the distributions versus disorder.
Lighter colours are higher disorder strengths.</code></pre>
<h2 id="entropy-distributions">Entropy distributions</h2>
<figure>
<img src="C:\Users\jaker\Documents\ent_loc\dat\ent_data\L13_dat\out\03_VN_Entropy_distribution.png" alt="text" /><figcaption>text</figcaption>
</figure>
<p>Probability density of the single-site Von Neumann entropy (upper left), Density plot of the Von Neumann entropy distribution versus disorder bandwidth (upper right), Logscale plot of the PDF of the Von Neumann entropy distribution (lower left), Shannon entropy of the PDF of the Von Neumann entropy (lower right) In the upper right, lighter colours are higher density. Otherwise, more disordered. # Properties of <span class="math inline">ℵ</span></p>
<p>Define the matrix <span class="math inline">ℵ</span> by setting the diagonal elements to the von Neumann entropy of the corresponding spin. <span class="math inline">ℵ</span> has similar properties to <span class="math inline"><em>L</em></span>, but <span class="math inline">ℵ</span> displays richer and more distinct variability, displaying the transformation from a simple unimodal distribution to a varied spectrum with at least five tiers of structure which are not visible in other constructions. The log-spectrum of <span class="math inline">ℵ</span> also show three distinct regimes across the localization transition.</p>
<h2 id="spectrum">Spectrum</h2>
<figure>
<img src="C:\Users\jaker\Documents\ent_loc\dat\ent_data\L13_dat\out\06_Aleph_spectral_distribution.png" alt="alephspec" /><figcaption>alephspec</figcaption>
</figure>
<pre><code>Probability distributions of the eigenvalues of Aleph  (upper &amp; mid left),
the PDFs of the log of the eigenvalues (upper &amp; mid right),
and the Shannon entropy (lower row) of the distributions versus disorder.
Lighter colours are higher disorder strengths.</code></pre>
<h2 id="trace">Trace</h2>
<figure>
<img src="C:\Users\jaker\Documents\ent_loc\dat\ent_data\L13_dat\out\07_Aleph_trace_distribution.png" alt="alephtr" /><figcaption>alephtr</figcaption>
</figure>
<pre><code>Probability distributions of the trace of the Aleph (upper &amp; mid left),
the PDFs of the log of the trace (upper &amp; mid right),
and the Shannon entropy (lower row) of the distributions versus disorder.
Lighter colours are higher disorder strengths.</code></pre>
<h1 id="section">=============================================================================</h1>
<h1 id="todo">TODO</h1>
<ul>
<li>Centrality measures</li>
<li>replace images with web links</li>
<li>Correlation lengths &amp; graph linear algebra - length scales</li>
<li>Scaling</li>
<li>Find appropriate distribution form</li>
<li>Plot scale parameters vs W &amp; guess functional form</li>
<li>Pick a reference length &amp; apply scaling transform</li>
<li>Extend to bose hubbard model</li>
</ul>
<h1 id="centrality">Centrality</h1>
<p>One can phrase the question of centrality in other ways. For example, given a node of high degree, how likely is it to be connected to other nodes of high degree? Figure 3 shows the PDF and CDF of the weighted mean of neighbours. <span class="math inline"><em>μ</em></span> compares the mean of the degree of the neighbours of <span class="math inline"><em>i</em></span> to the mean degree of all nodes other than <span class="math inline"><em>i</em></span>. A value of <span class="math inline"><em>μ</em><sub><em>i</em></sub> = 0</span> shows that system <span class="math inline"><em>i</em></span> is poorly connected, as either it has neighbours of low degree or it has only weak connections or both. A large <span class="math inline"><em>μ</em><sub><em>i</em></sub></span> indicates that the nodes connected strongly to system <span class="math inline"><em>i</em></span> are also strongly connected relative to the mean, and so form a central cluster in the global system. For the localized phase, the distribution of <span class="math inline"><em>μ</em></span> peaks sharply at 1, showing that almost all nodes are equally central - the graph is nearly uniformly completely connected.</p>
